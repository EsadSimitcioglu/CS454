{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLP and MLP in Pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn                              # neural network module\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim                        # optimization module\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter  # logging module\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\" Custom dataset for flattened 10x10 csv dataset \"\"\"\n",
    "\n",
    "    # Initialize data\n",
    "    def __init__(self, fname, transform=None):\n",
    "        self.xy = np.genfromtxt(fname, delimiter=',', skip_header=1, dtype=np.uint8)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.xy[index, 1:].reshape(10,10,1) # H W C\n",
    "        y = self.xy[index, 0]\n",
    "        y = torch.as_tensor(y, dtype=torch.long)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.xy.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch parameters\n",
    "SEED = 60            # reproducability\n",
    "# NN Parameters\n",
    "EPOCHS = 200         # number of epochs\n",
    "LR = 0.01            # learning rate\n",
    "MOMENTUM = 0.9       # momentum for the SGD optimizer (how much of the past gradients)\n",
    "GAMMA = 0.1          # learning rate scheduler (how much to decrease learning rate)\n",
    "BATCH_SIZE = 64      # number of images to load per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13d673883f0>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual seed to reproduce the same results\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform input data type from ndarray to tensor values between 0,1\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the datasets\n",
    "tr_dataset   = CustomDataset('data/training.csv', transform=transform)\n",
    "# prepare loader for the training dataset\n",
    "train_loader = torch.utils.data.DataLoader(tr_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# download the dataset if not already downloaded and set necessery transforms\n",
    "test_dataset = CustomDataset('data/testing.csv', transform=transform)\n",
    "# prepare loader for the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All networks derive from the base class nn.Module\n",
    "class N1(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    # ====== ENCODER PART ======       \n",
    "    # MNIST image is 1x28x28 (CxHxW)\n",
    "    # Pytorch convolution expects input data in the form BxCxHxW \n",
    "    # B: Batch size\n",
    "    # C: number of channels gray scale images have 1 channel\n",
    "    # W: width of the image \n",
    "    # H: height of the image\n",
    "\n",
    "    # use 32 3x3 filters with padding\n",
    "    # padding is set to 1 so that image W,H is not changed after convolution\n",
    "    # stride is 2 so filters will move 2 pixels for next calculation  \n",
    "    # W after conv2d  [(W - Kernelw + 2*padding)/stride] + 1\n",
    "    # after convolution we'll have Bx32 14x14 feature maps (28-3+2)/2 + 1 = 14\n",
    "    # (28-+9)/1 + 1\n",
    "    def __init__(self) :\n",
    "        # all derived classes must call __init__ method of super class\n",
    "        super(N1, self).__init__()\n",
    "\n",
    "        # [(W - Kernelw + 2*padding)/stride] + 1\n",
    "        # 10 - 3 + 6)/1 + 1 = 14\n",
    "        # 10 - 4 + 6)/2 + 1 = 7\n",
    "\n",
    "        # 10 - 3 + 6)/1 + 1 = 14\n",
    "        # 10 - 7 + 6)/1 + 1 = 10\n",
    "\n",
    "        self.c1 = nn.Conv2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=16,\n",
    "                            kernel_size=3,\n",
    "                            stride = 1,\n",
    "                            padding=3\n",
    "        )\n",
    "\n",
    "        # 14 - 3 + 6 )/1 + 1 = 18\n",
    "        # 7 - 4 + 6)/2 + 1 = 5\n",
    "\n",
    "        # 14 - 3 + 6)/1 + 1 = 18\n",
    "        # 10 - 7 + 6)/1 + 1 = 10\n",
    "        \n",
    "        self.c2 = nn.Conv2d(\n",
    "                            in_channels=16,\n",
    "                            out_channels=32,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding = 3\n",
    "        )\n",
    "\n",
    "        # 18 - 3 + 6 ) / 1 + 1 = 21\n",
    "\n",
    "        # 18 - 3 + 6)/1 + 1 = 22\n",
    "        # 10 - 7 + 6)/1 + 1 = 10\n",
    "\n",
    "        self.c3 = nn.Conv2d(\n",
    "                            in_channels=32,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding = 3\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64*22*22,10)\n",
    "        self.model = nn.Sequential(\n",
    "            self.c1,\n",
    "            self.c2,\n",
    "            self.c3,\n",
    "            self.fc1\n",
    "        )\n",
    "\n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.c1(x))\n",
    "        x = torch.relu(self.c2(x))\n",
    "        x = torch.relu(self.c3(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = (self.fc1(x))\n",
    "        return torch.log_softmax(x,dim=1)\n",
    "\n",
    "# Network with 2 convolutional layers different kernel_size, stride and padding\n",
    "class N2(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    def __init__(self):\n",
    "        # all derived classes must call init method of super class\n",
    "        super(N2, self).__init__()\n",
    "\n",
    "        # [(W - Kernelw + 2*padding)/stride] + 1\n",
    "        # 10 - 3 + 6) / 1 + 1 = 14\n",
    "        # 10 - 4 + 6) / 2 + 1 = 7\n",
    "\n",
    "        # 10 - 3 + 6) / 1 + 1 = 14\n",
    "        # 10 - 7 + 6) / 1 + 1 = 10\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=16,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=3\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(16*14*14, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.fc1\n",
    "        )\n",
    "        \n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = (self.fc1(x))\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class N3(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    def __init__(self):\n",
    "        # all derived classes must call __init__ method of super class\n",
    "        super(N3, self).__init__()\n",
    "        self.rel    = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=16,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=3\n",
    "        )\n",
    "        # [(W - Kernelw + 2*padding)/stride] + 1\n",
    "        # 10 - 4 + 6) / 1 + 1 = 13\n",
    "        # 10 - 4 + 6) / 2 + 1 = 7\n",
    "\n",
    "        # 10 - 3 + 6) / 1 + 1 = 14\n",
    "        # 10 - 7 + 6) / 1 + 1 = 10\n",
    "\n",
    "        self.fc1 = nn.Linear(16*14*14, 10)\n",
    "\n",
    "        \n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        x = self.rel(self.conv1(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        return torch.log_softmax(x, dim=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a network instance and move it to the device you want to run computations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.weight torch.Size([16, 1, 3, 3])\n",
      "c1.bias torch.Size([16])\n",
      "c2.weight torch.Size([32, 16, 3, 3])\n",
      "c2.bias torch.Size([32])\n",
      "c3.weight torch.Size([64, 32, 3, 3])\n",
      "c3.bias torch.Size([64])\n",
      "fc1.weight torch.Size([10, 28224])\n",
      "fc1.bias torch.Size([10])\n",
      "CUDA is avaliable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "N1(\n",
       "  (c1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "  (c2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "  (c3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "  (fc1): Linear(in_features=28224, out_features=10, bias=True)\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "    (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
       "    (3): Linear(in_features=28224, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the networkasdawasdawdasdasdasdasd\n",
    "net = N1()\n",
    "\n",
    "\n",
    "# print network parameter names and their size\n",
    "for name, param in net.named_parameters():\n",
    "  print(name, param.size())\n",
    "\n",
    "# check if CUDA is available\n",
    "cuda = torch.cuda.is_available()  \n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "if cuda:\n",
    "  print(\"CUDA is avaliable\")\n",
    "\n",
    "# if cuda is available move the network to gpu\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the loss to be used\n",
    "# softmax is internally computed.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# specify the optimizer to update the weights during backward pass\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "# change learning rate over time\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=GAMMA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net():\n",
    "  # put the network in training mode\n",
    "  net.train()\n",
    "  # keep record of the loss value\n",
    "  epoch_loss = 0.0\n",
    "  # use training data as batches\n",
    "  for xt, rt in train_loader:\n",
    "    # move training instances and corresponding labels into gpu if cuda is available\n",
    "    xt, rt = xt.to(device), rt.to(device)\n",
    "    # clear the previously accumulated gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward the network\n",
    "    yt = net(xt)\n",
    "    # calculate loss\n",
    "    loss = loss_fn(yt, rt)\n",
    "    # make a backward pass, calculate gradients\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    # accumulate loss\n",
    "    epoch_loss += loss.item()\n",
    "  return epoch_loss\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(loader):\n",
    "  # put the network in evaluation mode\n",
    "  net.eval()\n",
    "  # keep record of the loss value\n",
    "  total_loss = 0.0\n",
    "  # number of correctly classified instances\n",
    "  correct = 0\n",
    "  # disable gradient tracking\n",
    "  with torch.no_grad():\n",
    "    for xt, rt in loader:\n",
    "      # move training instances and corresponding labels into gpu if cuda is available\n",
    "      xt, rt = xt.to(device), rt.to(device)\n",
    "      # save_image(xt, f'images/sample_grid.png')  # save 8 images\n",
    "      # x = 8/0\n",
    "      # forward the network\n",
    "      yt = net(xt)\n",
    "      # calculate loss\n",
    "      loss = loss_fn(yt, rt)\n",
    "      # accumulate loss\n",
    "      total_loss += loss.item()\n",
    "      # get predicted classes\n",
    "      pred = yt.argmax(dim=1)\n",
    "      # accumulate correctly classified image counts\n",
    "      correct += (pred == rt).sum().item()\n",
    "      #correct += pred.eq(rt.view_as(pred)).sum().item()\n",
    "  return correct/len(loader.dataset), total_loss \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x30976 and 28224x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25668/3567990347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# train network for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;31m# get accuracy and loss on the training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25668/1748551859.py\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# forward the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0myt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25668/4031795330.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x30976 and 28224x10)"
     ]
    }
   ],
   "source": [
    "# initialize the logger instance\n",
    "# by default creates run directory inside current folder\n",
    "writer = SummaryWriter()           \n",
    "# train the network\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "  # train network for one epoch\n",
    "  train_net()\n",
    "  scheduler.step()\n",
    "  # get accuracy and loss on the training dataset\n",
    "  tr_ac, tr_loss = eval_net(train_loader)\n",
    "  # get accuracy and loss on the test dataset\n",
    "  tt_ac, tt_loss = eval_net(test_loader)\n",
    "  # save stats\n",
    "  writer.add_scalars(\"Loss\", {\"tr_loss\": tr_loss, \"tt_loss\":tt_loss} , epoch)\n",
    "  writer.add_scalars(\"Accuracy\", {\"tr_acc\": tr_ac, \"tt_acc\":tt_ac}, epoch)\n",
    "\n",
    "  if (epoch-1) % 10 == 0:\n",
    "    print(\"Epoch\", epoch, \"Tr Acc:\",tr_ac, \"Tt_Ac\", tt_ac)\n",
    "\n",
    "\n",
    "  writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the network model\n",
    "torch.save(net.state_dict(), 'model/mlp.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8108), started 19:54:41 ago. (Use '!kill 8108' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-abb9d7fedd53b2a5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-abb9d7fedd53b2a5\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n",
    "# open http://localhost:6006/ to view the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kill 4081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25668/783442862.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "weights.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('p37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ab66cd2a7eef53324163067b08cf46878006a1ba8ec8ccae931ca78a06f8215e"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
